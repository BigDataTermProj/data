{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28372, 31)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/imseonho/Downloads/tcc_ceds_music 3.csv')\n",
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /Users/imseonho/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/imseonho/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     /Users/imseonho/nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/imseonho/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/imseonho/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/imseonho/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/imseonho/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/imseonho/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download([\n",
    "     \"names\",\n",
    "     \"stopwords\",\n",
    "     \"state_union\",\n",
    "    \"twitter_samples\",\n",
    "     \"movie_reviews\",\n",
    "     \"averaged_perceptron_tagger\",\n",
    "     \"vader_lexicon\",\n",
    "     \"punkt\",\n",
    " ])\n",
    " \n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       release_date                                             lyrics\n",
      "0              1950  hold time feel break feel untrue convince spea...\n",
      "1              1950  believe drop rain fall grow believe darkest ni...\n",
      "2              1950  sweetheart send letter goodbye secret feel bet...\n",
      "3              1950  kiss lips want stroll charm mambo chacha merin...\n",
      "4              1950  till darling till matter know till dream live ...\n",
      "...             ...                                                ...\n",
      "28367          2019  cause fuck leave scar tick tock clock come kno...\n",
      "28368          2019  minks things chain ring braclets yap fame come...\n",
      "28369          2019  get ban get ban stick crack relax plan attack ...\n",
      "28370          2019  check check yeah yeah hear thing call switch g...\n",
      "28371          2019  remix killer alive remix thriller trap bitch s...\n",
      "\n",
      "[28372 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "parsedData=df[['release_date', 'lyrics']]\n",
    "print(parsedData)\n",
    "result=[]\n",
    "result.extend(parsedData['lyrics'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia_result = []\n",
    "for i in range(len(parsedData)):\n",
    "    result=[]\n",
    "    result.extend(parsedData.loc[i]['lyrics'])\n",
    "    #print(i)\n",
    "    #for j in result:\n",
    "    sia.polarity_scores(parsedData.loc[i]['lyrics'])\n",
    "    #print(sia.polarity_scores(parsedData.loc[i]['lyrics']))\n",
    "    #print('---')\n",
    "    #parsedData.loc[i]['sentiment'] = sia.polarity_scores(parsedData.loc[i]['lyrics'])\n",
    "    sia_result.append(sia.polarity_scores(parsedData.loc[i]['lyrics']))\n",
    "    #parsedData.insert(loc=i, 'sentiment', sia.polarity_scores(parsedData.loc[i]['lyrics']))\n",
    "    \n",
    "    #print(sia.polarity_scores(j))\n",
    "        \n",
    "    #print(parsedData.loc[i])\n",
    "    \n",
    "parsedData.insert(loc=1, column='sentiment', value=sia_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       release_date                                          sentiment  \\\n",
      "0              1950  {'neg': 0.233, 'neu': 0.467, 'pos': 0.3, 'comp...   \n",
      "1              1950  {'neg': 0.259, 'neu': 0.591, 'pos': 0.15, 'com...   \n",
      "2              1950  {'neg': 0.0, 'neu': 0.695, 'pos': 0.305, 'comp...   \n",
      "3              1950  {'neg': 0.04, 'neu': 0.458, 'pos': 0.502, 'com...   \n",
      "4              1950  {'neg': 0.134, 'neu': 0.494, 'pos': 0.372, 'co...   \n",
      "...             ...                                                ...   \n",
      "28367          2019  {'neg': 0.228, 'neu': 0.685, 'pos': 0.087, 'co...   \n",
      "28368          2019  {'neg': 0.242, 'neu': 0.539, 'pos': 0.219, 'co...   \n",
      "28369          2019  {'neg': 0.19, 'neu': 0.634, 'pos': 0.176, 'com...   \n",
      "28370          2019  {'neg': 0.068, 'neu': 0.706, 'pos': 0.226, 'co...   \n",
      "28371          2019  {'neg': 0.508, 'neu': 0.382, 'pos': 0.109, 'co...   \n",
      "\n",
      "                                                  lyrics  \n",
      "0      hold time feel break feel untrue convince spea...  \n",
      "1      believe drop rain fall grow believe darkest ni...  \n",
      "2      sweetheart send letter goodbye secret feel bet...  \n",
      "3      kiss lips want stroll charm mambo chacha merin...  \n",
      "4      till darling till matter know till dream live ...  \n",
      "...                                                  ...  \n",
      "28367  cause fuck leave scar tick tock clock come kno...  \n",
      "28368  minks things chain ring braclets yap fame come...  \n",
      "28369  get ban get ban stick crack relax plan attack ...  \n",
      "28370  check check yeah yeah hear thing call switch g...  \n",
      "28371  remix killer alive remix thriller trap bitch s...  \n",
      "\n",
      "[28372 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(parsedData)\n",
    "parsedData.to_csv('Lyrics Sentimental Analysis Result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0  year  suicide_no  population\n",
      "0            0  1985       29446   220723000\n",
      "1            1  1986       30892   222953000\n",
      "2            2  1987       30783   225148000\n",
      "3            3  1988       30388   227353000\n",
      "4            4  1989       30218   229487000\n",
      "5            5  1990       30895   229952200\n",
      "6            6  1991       30790   232955000\n",
      "7            7  1992       30471   235565600\n",
      "8            8  1993       31084   238092300\n",
      "9            9  1994       31123   240614100\n",
      "10          10  1995       31272   243164200\n",
      "11          11  1996       30879   245997800\n",
      "12          12  1997       30517   248486400\n",
      "13          13  1998       30558   251332500\n",
      "14          14  1999       29183   253748671\n",
      "15          15  2000       29343   262246108\n",
      "16          16  2001       30607   265427546\n",
      "17          17  2002       31645   268759559\n",
      "18          18  2003       31477   271041510\n",
      "19          19  2004       32428   273584136\n",
      "20          20  2005       32629   276106680\n",
      "21          21  2006       33292   278980848\n",
      "22          22  2007       34596   280658606\n",
      "23          23  2008       36030   282355565\n",
      "24          24  2009       36900   285162662\n",
      "25          25  2010       38362   287839149\n",
      "26          26  2011       39508   290313825\n",
      "27          27  2012       40596   292827128\n",
      "28          28  2013       41143   295322862\n",
      "29          29  2014       42769   297749735\n",
      "30          30  2015       44189   300078511\n"
     ]
    }
   ],
   "source": [
    "f = pd.read_csv('/Users/imseonho/bigdatatermproject/Preprocessed United States Suicide Data.csv')\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank  Previous Rank                                         Track Name  \\\n",
      "0      1            NaN                      Heart & Soul / Alligator Walk   \n",
      "1      2            2.0                                      Super Gremlin   \n",
      "2      3           65.0                                              Woman   \n",
      "3      4            1.0  Who Want Smoke?? (feat. G Herbo, 릴 더크 & 21 Sav...   \n",
      "4      5            5.0                    All I Want For Christmas Is You   \n",
      "..   ...            ...                                                ...   \n",
      "95    96           68.0                                 You Are The Reason   \n",
      "96    97           69.0               Love Me (feat. Drake(드레이크) & FUTURE)   \n",
      "97    98            NaN                   Sinister (feat. Lil Wayne(릴 웨인))   \n",
      "98    99           66.0                                         Let Her Go   \n",
      "99   100            NaN                                Male Fantasy (Live)   \n",
      "\n",
      "                  Artist Names  Weeks on Chart    Views Weekly Growth  \\\n",
      "0   Youngboy Never Broke Again               1  9916215           NaN   \n",
      "1                        코닥 블랙               6  7720267         38.9%   \n",
      "2                Doja Cat(도자캣)              19  6354793        389.7%   \n",
      "3                   Nardo Wick               9  5474045         -2.3%   \n",
      "4                      머라이어 캐리              45  5399879         20.3%   \n",
      "..                         ...             ...      ...           ...   \n",
      "95                 Calum Scott              16  1278312          2.7%   \n",
      "96             Lil Wayne(릴 웨인)               8  1262488          2.6%   \n",
      "97                      Cordae               1  1256973           NaN   \n",
      "98              Passenger(패신저)              19  1226537         -4.9%   \n",
      "99      Billie Eilish(빌리 아일리시)               1  1224408           NaN   \n",
      "\n",
      "                                    YouTube URL  \n",
      "0   https://www.youtube.com/watch?v=NvKjO-8DusE  \n",
      "1   https://www.youtube.com/watch?v=kiB9qk4gnt4  \n",
      "2   https://www.youtube.com/watch?v=2V_uAAAH-_Q  \n",
      "3   https://www.youtube.com/watch?v=U2SNwtE-0Us  \n",
      "4   https://www.youtube.com/watch?v=aAkMkVFwAoo  \n",
      "..                                          ...  \n",
      "95  https://www.youtube.com/watch?v=ShZ978fBl6Y  \n",
      "96  https://www.youtube.com/watch?v=KY44zvhWhp4  \n",
      "97  https://www.youtube.com/watch?v=9VYj6CFnO08  \n",
      "98  https://www.youtube.com/watch?v=RBumgq5yVrA  \n",
      "99  https://www.youtube.com/watch?v=i7YvaaAkRCw  \n",
      "\n",
      "[100 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "ff = pd.read_csv('/Users/imseonho/Downloads/youtube-charts-top-songs-us-weekly-2021-12-09.csv')\n",
    "\n",
    "print(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
